{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages, which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission if necessary. \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission. \n",
    "\n",
    "In addition to implementing code, there is a writeup to complete. The writeup should be completed in a separate file, which can be either a markdown file or a pdf document. There is a [write up template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) that can be used to guide the writing process. Completing the code template and writeup template will cover all of the [rubric points](https://review.udacity.com/#!/rubrics/481/view) for this project.\n",
    "\n",
    "The [rubric](https://review.udacity.com/#!/rubrics/481/view) contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this Ipython notebook and also discuss the results in the writeup file.\n",
    "\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'train.p'\n",
    "validation_file= 'valid.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below. Use python, numpy and/or pandas methods to calculate the data summary rather than hard coding the results. For example, the [pandas shape method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html) might be useful for calculating some of the summary results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "import random\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "index = random.randint(0,n_train)\n",
    "image = X_train[index]\n",
    "image_shape = image.shape\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "uniqueClasses = set(y_train)\n",
    "n_classes = len(uniqueClasses)\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualize the German Traffic Signs Dataset using the pickled file(s). This is open ended, suggestions include: plotting traffic sign images, plotting the count of each sign, etc.\n",
    "\n",
    "The [Matplotlib](http://matplotlib.org/) [examples](http://matplotlib.org/examples/index.html) and [gallery](http://matplotlib.org/gallery.html) pages are a great resource for doing visualizations in Python.\n",
    "\n",
    "**NOTE:** It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFoAAABYCAYAAAB1YOAJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPDsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39295b9240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these.\n",
    "\n",
    "**NOTE:** The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here. Preprocessing steps could include normalization, converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "# suffle the data\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### epochs count and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LeNet \n",
    "simple implementation of lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    #dropout 1\n",
    "    hidden_drop1 = tf.nn.dropout(conv1, keep_prob)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(hidden_drop1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 43 (trafic signs).\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Features, Labels, One hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the test set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Cicle  1 Validation Accuracy = 0.152\n",
      "\n",
      "Cicle  2 Validation Accuracy = 0.395\n",
      "\n",
      "Cicle  3 Validation Accuracy = 0.552\n",
      "\n",
      "Cicle  4 Validation Accuracy = 0.622\n",
      "\n",
      "Cicle  5 Validation Accuracy = 0.741\n",
      "\n",
      "Cicle  6 Validation Accuracy = 0.764\n",
      "\n",
      "Cicle  7 Validation Accuracy = 0.809\n",
      "\n",
      "Cicle  8 Validation Accuracy = 0.832\n",
      "\n",
      "Cicle  9 Validation Accuracy = 0.844\n",
      "\n",
      "Cicle  10 Validation Accuracy = 0.863\n",
      "\n",
      "Cicle  11 Validation Accuracy = 0.875\n",
      "\n",
      "Cicle  12 Validation Accuracy = 0.865\n",
      "\n",
      "Cicle  13 Validation Accuracy = 0.875\n",
      "\n",
      "Cicle  14 Validation Accuracy = 0.877\n",
      "\n",
      "Cicle  15 Validation Accuracy = 0.883\n",
      "\n",
      "Cicle  16 Validation Accuracy = 0.879\n",
      "\n",
      "Cicle  17 Validation Accuracy = 0.868\n",
      "\n",
      "Cicle  18 Validation Accuracy = 0.874\n",
      "\n",
      "Cicle  19 Validation Accuracy = 0.901\n",
      "\n",
      "Cicle  20 Validation Accuracy = 0.875\n",
      "\n",
      "Cicle  21 Validation Accuracy = 0.884\n",
      "\n",
      "Cicle  22 Validation Accuracy = 0.900\n",
      "\n",
      "Cicle  23 Validation Accuracy = 0.900\n",
      "\n",
      "Cicle  24 Validation Accuracy = 0.894\n",
      "\n",
      "Cicle  25 Validation Accuracy = 0.909\n",
      "\n",
      "Cicle  26 Validation Accuracy = 0.902\n",
      "\n",
      "Cicle  27 Validation Accuracy = 0.902\n",
      "\n",
      "Cicle  28 Validation Accuracy = 0.911\n",
      "\n",
      "Cicle  29 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  30 Validation Accuracy = 0.896\n",
      "\n",
      "Cicle  31 Validation Accuracy = 0.892\n",
      "\n",
      "Cicle  32 Validation Accuracy = 0.913\n",
      "\n",
      "Cicle  33 Validation Accuracy = 0.907\n",
      "\n",
      "Cicle  34 Validation Accuracy = 0.919\n",
      "\n",
      "Cicle  35 Validation Accuracy = 0.919\n",
      "\n",
      "Cicle  36 Validation Accuracy = 0.917\n",
      "\n",
      "Cicle  37 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  38 Validation Accuracy = 0.902\n",
      "\n",
      "Cicle  39 Validation Accuracy = 0.894\n",
      "\n",
      "Cicle  40 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  41 Validation Accuracy = 0.910\n",
      "\n",
      "Cicle  42 Validation Accuracy = 0.903\n",
      "\n",
      "Cicle  43 Validation Accuracy = 0.894\n",
      "\n",
      "Cicle  44 Validation Accuracy = 0.916\n",
      "\n",
      "Cicle  45 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  46 Validation Accuracy = 0.919\n",
      "\n",
      "Cicle  47 Validation Accuracy = 0.902\n",
      "\n",
      "Cicle  48 Validation Accuracy = 0.906\n",
      "\n",
      "Cicle  49 Validation Accuracy = 0.909\n",
      "\n",
      "Cicle  50 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  51 Validation Accuracy = 0.910\n",
      "\n",
      "Cicle  52 Validation Accuracy = 0.916\n",
      "\n",
      "Cicle  53 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  54 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  55 Validation Accuracy = 0.912\n",
      "\n",
      "Cicle  56 Validation Accuracy = 0.932\n",
      "\n",
      "Cicle  57 Validation Accuracy = 0.913\n",
      "\n",
      "Cicle  58 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  59 Validation Accuracy = 0.928\n",
      "\n",
      "Cicle  60 Validation Accuracy = 0.919\n",
      "\n",
      "Cicle  61 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  62 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  63 Validation Accuracy = 0.922\n",
      "\n",
      "Cicle  64 Validation Accuracy = 0.919\n",
      "\n",
      "Cicle  65 Validation Accuracy = 0.929\n",
      "\n",
      "Cicle  66 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  67 Validation Accuracy = 0.920\n",
      "\n",
      "Cicle  68 Validation Accuracy = 0.912\n",
      "\n",
      "Cicle  69 Validation Accuracy = 0.910\n",
      "\n",
      "Cicle  70 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  71 Validation Accuracy = 0.916\n",
      "\n",
      "Cicle  72 Validation Accuracy = 0.924\n",
      "\n",
      "Cicle  73 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  74 Validation Accuracy = 0.923\n",
      "\n",
      "Cicle  75 Validation Accuracy = 0.920\n",
      "\n",
      "Cicle  76 Validation Accuracy = 0.924\n",
      "\n",
      "Cicle  77 Validation Accuracy = 0.933\n",
      "\n",
      "Cicle  78 Validation Accuracy = 0.907\n",
      "\n",
      "Cicle  79 Validation Accuracy = 0.931\n",
      "\n",
      "Cicle  80 Validation Accuracy = 0.916\n",
      "\n",
      "Cicle  81 Validation Accuracy = 0.921\n",
      "\n",
      "Cicle  82 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  83 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  84 Validation Accuracy = 0.910\n",
      "\n",
      "Cicle  85 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  86 Validation Accuracy = 0.914\n",
      "\n",
      "Cicle  87 Validation Accuracy = 0.922\n",
      "\n",
      "Cicle  88 Validation Accuracy = 0.920\n",
      "\n",
      "Cicle  89 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  90 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  91 Validation Accuracy = 0.930\n",
      "\n",
      "Cicle  92 Validation Accuracy = 0.917\n",
      "\n",
      "Cicle  93 Validation Accuracy = 0.933\n",
      "\n",
      "Cicle  94 Validation Accuracy = 0.930\n",
      "\n",
      "Cicle  95 Validation Accuracy = 0.907\n",
      "\n",
      "Cicle  96 Validation Accuracy = 0.927\n",
      "\n",
      "Cicle  97 Validation Accuracy = 0.930\n",
      "\n",
      "Cicle  98 Validation Accuracy = 0.927\n",
      "\n",
      "Cicle  99 Validation Accuracy = 0.923\n",
      "\n",
      "Cicle  100 Validation Accuracy = 0.932\n",
      "\n",
      "Cicle  101 Validation Accuracy = 0.924\n",
      "\n",
      "Cicle  102 Validation Accuracy = 0.928\n",
      "\n",
      "Cicle  103 Validation Accuracy = 0.914\n",
      "\n",
      "Cicle  104 Validation Accuracy = 0.924\n",
      "\n",
      "Cicle  105 Validation Accuracy = 0.929\n",
      "\n",
      "Cicle  106 Validation Accuracy = 0.921\n",
      "\n",
      "Cicle  107 Validation Accuracy = 0.921\n",
      "\n",
      "Cicle  108 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  109 Validation Accuracy = 0.931\n",
      "\n",
      "Cicle  110 Validation Accuracy = 0.920\n",
      "\n",
      "Cicle  111 Validation Accuracy = 0.925\n",
      "\n",
      "Cicle  112 Validation Accuracy = 0.919\n",
      "\n",
      "Cicle  113 Validation Accuracy = 0.927\n",
      "\n",
      "Cicle  114 Validation Accuracy = 0.932\n",
      "\n",
      "Cicle  115 Validation Accuracy = 0.933\n",
      "\n",
      "Cicle  116 Validation Accuracy = 0.921\n",
      "\n",
      "Cicle  117 Validation Accuracy = 0.927\n",
      "\n",
      "Cicle  118 Validation Accuracy = 0.907\n",
      "\n",
      "Cicle  119 Validation Accuracy = 0.931\n",
      "\n",
      "Cicle  120 Validation Accuracy = 0.925\n",
      "\n",
      "Cicle  121 Validation Accuracy = 0.928\n",
      "\n",
      "Cicle  122 Validation Accuracy = 0.938\n",
      "\n",
      "Cicle  123 Validation Accuracy = 0.930\n",
      "\n",
      "Cicle  124 Validation Accuracy = 0.925\n",
      "\n",
      "Cicle  125 Validation Accuracy = 0.933\n",
      "\n",
      "Cicle  126 Validation Accuracy = 0.934\n",
      "\n",
      "Cicle  127 Validation Accuracy = 0.922\n",
      "\n",
      "Cicle  128 Validation Accuracy = 0.932\n",
      "\n",
      "Cicle  129 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  130 Validation Accuracy = 0.933\n",
      "\n",
      "Cicle  131 Validation Accuracy = 0.923\n",
      "\n",
      "Cicle  132 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  133 Validation Accuracy = 0.920\n",
      "\n",
      "Cicle  134 Validation Accuracy = 0.920\n",
      "\n",
      "Cicle  135 Validation Accuracy = 0.922\n",
      "\n",
      "Cicle  136 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  137 Validation Accuracy = 0.921\n",
      "\n",
      "Cicle  138 Validation Accuracy = 0.934\n",
      "\n",
      "Cicle  139 Validation Accuracy = 0.917\n",
      "\n",
      "Cicle  140 Validation Accuracy = 0.917\n",
      "\n",
      "Cicle  141 Validation Accuracy = 0.919\n",
      "\n",
      "Cicle  142 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  143 Validation Accuracy = 0.923\n",
      "\n",
      "Cicle  144 Validation Accuracy = 0.936\n",
      "\n",
      "Cicle  145 Validation Accuracy = 0.936\n",
      "\n",
      "Cicle  146 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  147 Validation Accuracy = 0.912\n",
      "\n",
      "Cicle  148 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  149 Validation Accuracy = 0.921\n",
      "\n",
      "Cicle  150 Validation Accuracy = 0.928\n",
      "\n",
      "Cicle  151 Validation Accuracy = 0.911\n",
      "\n",
      "Cicle  152 Validation Accuracy = 0.930\n",
      "\n",
      "Cicle  153 Validation Accuracy = 0.935\n",
      "\n",
      "Cicle  154 Validation Accuracy = 0.922\n",
      "\n",
      "Cicle  155 Validation Accuracy = 0.911\n",
      "\n",
      "Cicle  156 Validation Accuracy = 0.925\n",
      "\n",
      "Cicle  157 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  158 Validation Accuracy = 0.917\n",
      "\n",
      "Cicle  159 Validation Accuracy = 0.904\n",
      "\n",
      "Cicle  160 Validation Accuracy = 0.915\n",
      "\n",
      "Cicle  161 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  162 Validation Accuracy = 0.925\n",
      "\n",
      "Cicle  163 Validation Accuracy = 0.921\n",
      "\n",
      "Cicle  164 Validation Accuracy = 0.911\n",
      "\n",
      "Cicle  165 Validation Accuracy = 0.931\n",
      "\n",
      "Cicle  166 Validation Accuracy = 0.929\n",
      "\n",
      "Cicle  167 Validation Accuracy = 0.932\n",
      "\n",
      "Cicle  168 Validation Accuracy = 0.932\n",
      "\n",
      "Cicle  169 Validation Accuracy = 0.933\n",
      "\n",
      "Cicle  170 Validation Accuracy = 0.927\n",
      "\n",
      "Cicle  171 Validation Accuracy = 0.924\n",
      "\n",
      "Cicle  172 Validation Accuracy = 0.937\n",
      "\n",
      "Cicle  173 Validation Accuracy = 0.925\n",
      "\n",
      "Cicle  174 Validation Accuracy = 0.924\n",
      "\n",
      "Cicle  175 Validation Accuracy = 0.924\n",
      "\n",
      "Cicle  176 Validation Accuracy = 0.921\n",
      "\n",
      "Cicle  177 Validation Accuracy = 0.908\n",
      "\n",
      "Cicle  178 Validation Accuracy = 0.927\n",
      "\n",
      "Cicle  179 Validation Accuracy = 0.930\n",
      "\n",
      "Cicle  180 Validation Accuracy = 0.928\n",
      "\n",
      "Cicle  181 Validation Accuracy = 0.918\n",
      "\n",
      "Cicle  182 Validation Accuracy = 0.936\n",
      "\n",
      "Cicle  183 Validation Accuracy = 0.909\n",
      "\n",
      "Cicle  184 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  185 Validation Accuracy = 0.934\n",
      "\n",
      "Cicle  186 Validation Accuracy = 0.898\n",
      "\n",
      "Cicle  187 Validation Accuracy = 0.930\n",
      "\n",
      "Cicle  188 Validation Accuracy = 0.933\n",
      "\n",
      "Cicle  189 Validation Accuracy = 0.929\n",
      "\n",
      "Cicle  190 Validation Accuracy = 0.929\n",
      "\n",
      "Cicle  191 Validation Accuracy = 0.932\n",
      "\n",
      "Cicle  192 Validation Accuracy = 0.927\n",
      "\n",
      "Cicle  193 Validation Accuracy = 0.917\n",
      "\n",
      "Cicle  194 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  195 Validation Accuracy = 0.931\n",
      "\n",
      "Cicle  196 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  197 Validation Accuracy = 0.926\n",
      "\n",
      "Cicle  198 Validation Accuracy = 0.934\n",
      "\n",
      "Cicle  199 Validation Accuracy = 0.929\n",
      "\n",
      "Cicle  200 Validation Accuracy = 0.923\n",
      "\n",
      "Cicle  201 Validation Accuracy = 0.906\n",
      "\n",
      "Cicle  202 Validation Accuracy = 0.930\n",
      "\n",
      "Cicle  203 Validation Accuracy = 0.935\n",
      "\n",
      "Cicle  204 Validation Accuracy = 0.941\n",
      "\n",
      "time to stop\n",
      "Model saved\n",
      "Final acurracy =  0.887981859194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    #for i in range(EPOCHS):\n",
    "    k=0;\n",
    "    running = True\n",
    "    while running:\n",
    "        k+=1\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:0.5})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        #if (i+1)%1 == 0 :\n",
    "            #print(\"EPOCH {} ...\".format(i+1))\n",
    "            #print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print(\"Cicle \", k, \"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        if (validation_accuracy > 0.940):\n",
    "            print (\"time to stop\")\n",
    "            running = False\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Test one time only on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.919\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    saver.restore(sess, './lenet')\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run some random test images throw the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "(32, 32, 3)\n",
      "my prediction [35]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFoAAABYCAYAAAB1YOAJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3928f05f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #get_argmax = tf.argmax(logits, 1)\n",
    "    saver.restore(sess, './lenet')\n",
    "    \n",
    "    index = random.randint(0,n_test)\n",
    "    image = X_test[index]\n",
    "    image_shape = image.shape\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(image)\n",
    "    print(y_train[index])\n",
    "    print(image_shape)\n",
    "    \n",
    "    prediction = sess.run(tf.argmax(logits, 1), feed_dict = {x: [image], keep_prob: 1.0})\n",
    "    print (\"my prediction\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction [13]\n"
     ]
    }
   ],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    code_35 = cv2.imread(\"bogdanData/code_35.png\")\n",
    "    cv2.imwrite(\"bogdanData/test1.png\",code_35)\n",
    "    #code_35 = code_35.flatten()/255.0\n",
    "    \n",
    "    saver.restore(sess, './lenet')\n",
    "    prediction = sess.run(tf.argmax(logits, 1), feed_dict = {x: [code_35], keep_prob: 1.0})\n",
    "    print (\"my prediction\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For each of the new images, print out the model's softmax probabilities to show the **certainty** of the model's predictions (limit the output to the top 5 probabilities for each image). [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. \n",
    "\n",
    "The example below demonstrates how tf.nn.top_k can be used to find the top k predictions for each image.\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example. The values in the array represent predictions. The array contains softmax probabilities for five candidate images with six possible classes. `tk.nn.top_k` is used to choose the three classes with the highest probability:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the IPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Project Writeup\n",
    "\n",
    "Once you have completed the code implementation, document your results in a project writeup using this [template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) as a guide. The writeup can be in a markdown or pdf file. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
